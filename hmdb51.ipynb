{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "hmdb51.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b17db7ac"
      },
      "source": [
        "### Import packages"
      ],
      "id": "b17db7ac"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hkchx3qMEaWM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53c9de2b-a539-46da-db61-a75cc7a2f2b3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "Hkchx3qMEaWM",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "643648c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43a8a1da-2eac-4fa9-fb86-36920646807b"
      },
      "source": [
        "import torch, torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import cv2\n",
        "import os\n",
        "from os import path\n",
        "import json\n",
        "import time\n",
        "import copy\n",
        "\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "#if gpu, use it\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "id": "643648c0",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52f767d9"
      },
      "source": [
        "### Extract frames from videos and place them inside video name folder"
      ],
      "id": "52f767d9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73444b38"
      },
      "source": [
        "# def extract_frames(file_path, target_dir):\n",
        "#     if not os.path.exists(target_dir):\n",
        "#         os.makedirs(target_dir)\n",
        "\n",
        "#     vidcap = cv2.VideoCapture(file_path)\n",
        "#     success, image = vidcap.read()\n",
        "#     count = 0\n",
        " \n",
        "#     while success:\n",
        "#       frame_path = os.path.join(target_dir, f'{count}.jpg')\n",
        "#       cv2.imwrite(frame_path, image)     # save frame as JPEG file\n",
        "#       count += 1\n",
        "#       success, image = vidcap.read()\n",
        "#       success, image = vidcap.read()\n",
        "#       success, image = vidcap.read()\n",
        "\n",
        "\n",
        "# root = '/content/drive/MyDrive/mini_dataset'\n",
        "# frame_root = '/content/drive/MyDrive/teste/hmdb51_frames'\n",
        "# labels_path = '/content/drive/MyDrive/teste/labels.csv'\n",
        "# class_name_to_label_path = '/content/drive/MyDrive/teste/class_name_to_label.json'\n",
        "\n",
        "# # read files\n",
        "# files = []\n",
        "\n",
        "# for class_name in os.listdir(root):\n",
        "#     for video_name in os.listdir(os.path.join(root, class_name)):\n",
        "#         files.append([os.path.join(class_name, video_name), class_name])\n",
        "\n",
        "# # normalize labels\n",
        "# class_name_to_label = {}\n",
        "# current_label = -1\n",
        "\n",
        "# for vid in files:\n",
        "#     label = class_name_to_label.get(vid[1], -1)\n",
        "\n",
        "#     if label == -1:\n",
        "#         current_label += 1\n",
        "#         class_name_to_label[vid[1]] = current_label\n",
        "#         label = current_label\n",
        "\n",
        "#     vid[1] = label\n",
        "\n",
        "\n",
        "# # save file paths\n",
        "# if not os.path.exists(os.path.split(labels_path)[0]):\n",
        "#     os.makedirs(os.path.split(labels_path)[0])\n",
        "\n",
        "# f = open(labels_path, 'w')\n",
        "\n",
        "# f.write('path,label\\n')\n",
        "\n",
        "# for vid in files:\n",
        "#     f.write(f'{vid[0]},{vid[1]}\\n')\n",
        "\n",
        "# f.close()\n",
        "\n",
        "# # save label normalization\n",
        "# if not os.path.exists(os.path.split(class_name_to_label_path)[0]):\n",
        "#     os.makedirs(os.path.split(class_name_to_label_path)[0])\n",
        "\n",
        "# with open(class_name_to_label_path, 'w') as json_file:\n",
        "#     json.dump(class_name_to_label, json_file, indent=4)\n",
        "\n",
        "# # extract frames\n",
        "# for i, vid in enumerate(files):\n",
        "#     file_path = os.path.join(root, vid[0])\n",
        "#     target_dir = os.path.join(frame_root, vid[0])\n",
        "\n",
        "#     extract_frames(file_path, target_dir)\n",
        "\n",
        "#     print(f'{i+1}/{len(files)}')\n"
      ],
      "id": "73444b38",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f649ccd"
      },
      "source": [
        "### Split labels csv file into train and validate - 80/20"
      ],
      "id": "6f649ccd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "623bdf86"
      },
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# def split(label):\n",
        "#     path = '/content/drive/MyDrive/teste'\n",
        "#     train = label.sample(frac=0.8, random_state=201)\n",
        "#     val = label.drop(train.index)\n",
        "#     train.to_csv(path + '/train.csv', mode='a', header=False)\n",
        "#     val.to_csv(path + '/val.csv', mode='a', header=False)\n",
        "\n",
        "\n",
        "# root = '/content/drive/MyDrive/teste'\n",
        "# frame_root = '/content/drive/MyDrive/teste/hmdb51_frames'\n",
        "# labels_path = '/content/drive/MyDrive/teste/labels.csv'\n",
        "# class_name_to_label_path = '/content/drive/MyDrive/teste/class_name_to_label.json'\n",
        "\n",
        "# labels_path = '/content/drive/MyDrive/teste/labels.csv'\n",
        "# labels_data = pd.read_csv(labels_path)\n",
        "# last_label = labels_data.tail(1)['label']\n",
        "# last_label = last_label.iloc[0]\n",
        "# max_labels = labels_data.nunique()\n",
        "# max_labels= max_labels['label']\n",
        "# index = 0\n",
        "\n",
        "# for i in range(max_labels):\n",
        "#     label = labels_data[labels_data['label'] == index]\n",
        "#     split(label)\n",
        "#     index +=1 \n"
      ],
      "id": "623bdf86",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b06b0bbb"
      },
      "source": [
        "### Custom Dataset"
      ],
      "id": "b06b0bbb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3805f1c9"
      },
      "source": [
        "train_csv_path = '/content/drive/MyDrive/teste/train.csv'\n",
        "validate_csv_path = '/content/drive/MyDrive/teste/val.csv'\n",
        "root_path = '/content/drive/MyDrive/teste/hmdb51_frames'\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self, frames_csv_file, root_dir):\n",
        "    self.frames_csv = pd.read_csv(frames_csv_file)\n",
        "    self.root_dir = root_dir\n",
        "    self.slice_size = 10\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.frames_csv)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      if torch.is_tensor(idx):\n",
        "          idx = idx.tolist()\n",
        "      \n",
        "      #need to take 10 frames and stack them on 1                                                    \n",
        "                                                                            #second index has to be 1 because id column (3 columns) \n",
        "                                                                                                        #why have to be NOT??? is wrong!! but works..\n",
        "      all_frames = [f for f in os.listdir(os.path.join(self.root_dir, str(self.frames_csv.iloc[idx, 1]))) if not os.path.isfile(f)]\n",
        "      images = []\n",
        "      for frame in all_frames:\n",
        "        path = os.path.join(self.root_dir, str(self.frames_csv.iloc[idx, 1])) + '/' + frame\n",
        "        images.append(Image.open(path).convert('RGB'))\n",
        "      #random get 10 consecutive frames from all video images\n",
        "      if len(images) > (self.slice_size - 1):\n",
        "        start = random.randrange(len(images) - 10)\n",
        "        frames = images[start: start + self.slice_size]\n",
        "      #apply tansforms and condense all the frames in 1 tensor\n",
        "      final_image = self.transform(frames)\n",
        "      tag = int(self.frames_csv.iloc[idx, 2])\n",
        "      sample = {'image': final_image, 'tag': tag}\n",
        "      return sample\n",
        "\n",
        "  def transform(self, frames):\n",
        "    #random crop\n",
        "    #random horizontal flip\n",
        "    #transform to tensor and stack\n",
        "    frames_tensors = []\n",
        "    for frame in frames:\n",
        "      #rezise image\n",
        "      newsize = (240, 320)\n",
        "      frame = frame.resize(newsize)\n",
        "      frame = TF.to_tensor(frame)\n",
        "      frames_tensors.append(frame)\n",
        "    final_tensor = torch.stack(frames_tensors, dim=1)\n",
        "    #normalize\n",
        "\n",
        "    return final_tensor\n",
        "\n",
        "train_dataset = MyDataset(train_csv_path, root_path)\n",
        "validate_dataset = MyDataset(validate_csv_path, root_path)\n",
        "\n"
      ],
      "id": "3805f1c9",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IujiHxXEUMH"
      },
      "source": [
        "## Dataloaders"
      ],
      "id": "0IujiHxXEUMH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFRJQ66ZER4P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96a8ed36-a8e9-4998-ea35-6568778759dd"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "validate_dataloader = DataLoader(validate_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "sample = iter(validate_dataloader).next()\n",
        "print('tensor: ', end='  ')\n",
        "print(sample['image'])\n",
        "print('tag: ', end='  ')\n",
        "print(sample['tag'])\n"
      ],
      "id": "jFRJQ66ZER4P",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor:   tensor([[[[[0.3882, 0.3882, 0.3882,  ..., 0.5020, 0.5020, 0.5020],\n",
            "           [0.3882, 0.3882, 0.3882,  ..., 0.5059, 0.5059, 0.5059],\n",
            "           [0.3882, 0.3882, 0.3882,  ..., 0.5137, 0.5137, 0.5137],\n",
            "           ...,\n",
            "           [0.0392, 0.0392, 0.0353,  ..., 0.0902, 0.0980, 0.1098],\n",
            "           [0.0353, 0.0353, 0.0314,  ..., 0.0745, 0.0784, 0.0941],\n",
            "           [0.0275, 0.0275, 0.0275,  ..., 0.0627, 0.0667, 0.0824]],\n",
            "\n",
            "          [[0.3804, 0.3843, 0.3882,  ..., 0.5020, 0.5020, 0.5020],\n",
            "           [0.3804, 0.3843, 0.3882,  ..., 0.5059, 0.5059, 0.5059],\n",
            "           [0.3804, 0.3843, 0.3882,  ..., 0.5137, 0.5137, 0.5137],\n",
            "           ...,\n",
            "           [0.0353, 0.0353, 0.0314,  ..., 0.0902, 0.0980, 0.1098],\n",
            "           [0.0314, 0.0314, 0.0314,  ..., 0.0745, 0.0784, 0.0941],\n",
            "           [0.0275, 0.0275, 0.0275,  ..., 0.0627, 0.0667, 0.0824]],\n",
            "\n",
            "          [[0.3882, 0.3882, 0.3882,  ..., 0.5020, 0.5020, 0.5020],\n",
            "           [0.3882, 0.3882, 0.3882,  ..., 0.5059, 0.5059, 0.5059],\n",
            "           [0.3882, 0.3882, 0.3882,  ..., 0.5137, 0.5137, 0.5137],\n",
            "           ...,\n",
            "           [0.0353, 0.0353, 0.0314,  ..., 0.0902, 0.0980, 0.1098],\n",
            "           [0.0314, 0.0314, 0.0314,  ..., 0.0745, 0.0784, 0.0941],\n",
            "           [0.0275, 0.0275, 0.0275,  ..., 0.0627, 0.0667, 0.0824]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[0.3804, 0.3804, 0.3843,  ..., 0.5020, 0.5020, 0.5020],\n",
            "           [0.3804, 0.3804, 0.3843,  ..., 0.5059, 0.5059, 0.5059],\n",
            "           [0.3804, 0.3804, 0.3843,  ..., 0.5137, 0.5137, 0.5137],\n",
            "           ...,\n",
            "           [0.0353, 0.0353, 0.0353,  ..., 0.0902, 0.0549, 0.0902],\n",
            "           [0.0353, 0.0353, 0.0353,  ..., 0.0784, 0.0392, 0.0745],\n",
            "           [0.0392, 0.0353, 0.0314,  ..., 0.0627, 0.0275, 0.0667]],\n",
            "\n",
            "          [[0.3882, 0.3882, 0.3882,  ..., 0.5020, 0.5059, 0.5059],\n",
            "           [0.3882, 0.3882, 0.3882,  ..., 0.5020, 0.5059, 0.5059],\n",
            "           [0.3882, 0.3882, 0.3882,  ..., 0.5020, 0.5059, 0.5059],\n",
            "           ...,\n",
            "           [0.0392, 0.0392, 0.0353,  ..., 0.0667, 0.0745, 0.0824],\n",
            "           [0.0392, 0.0392, 0.0392,  ..., 0.0431, 0.0627, 0.0667],\n",
            "           [0.0392, 0.0392, 0.0392,  ..., 0.0314, 0.0549, 0.0588]],\n",
            "\n",
            "          [[0.3882, 0.3882, 0.3882,  ..., 0.5020, 0.5020, 0.5020],\n",
            "           [0.3882, 0.3882, 0.3882,  ..., 0.5020, 0.5020, 0.5020],\n",
            "           [0.3882, 0.3882, 0.3882,  ..., 0.5020, 0.5020, 0.5020],\n",
            "           ...,\n",
            "           [0.0471, 0.0431, 0.0510,  ..., 0.0549, 0.0706, 0.0784],\n",
            "           [0.0471, 0.0431, 0.0510,  ..., 0.0314, 0.0588, 0.0627],\n",
            "           [0.0471, 0.0431, 0.0510,  ..., 0.0157, 0.0549, 0.0510]]],\n",
            "\n",
            "\n",
            "         [[[0.3686, 0.3686, 0.3686,  ..., 0.4863, 0.4863, 0.4863],\n",
            "           [0.3686, 0.3686, 0.3686,  ..., 0.4824, 0.4824, 0.4824],\n",
            "           [0.3686, 0.3686, 0.3686,  ..., 0.4784, 0.4784, 0.4784],\n",
            "           ...,\n",
            "           [0.0471, 0.0471, 0.0510,  ..., 0.0784, 0.0627, 0.0902],\n",
            "           [0.0549, 0.0549, 0.0588,  ..., 0.0784, 0.0667, 0.0941],\n",
            "           [0.0588, 0.0588, 0.0588,  ..., 0.0824, 0.0706, 0.0980]],\n",
            "\n",
            "          [[0.3647, 0.3686, 0.3725,  ..., 0.4863, 0.4863, 0.4863],\n",
            "           [0.3647, 0.3686, 0.3725,  ..., 0.4824, 0.4824, 0.4824],\n",
            "           [0.3647, 0.3686, 0.3725,  ..., 0.4784, 0.4784, 0.4784],\n",
            "           ...,\n",
            "           [0.0510, 0.0510, 0.0549,  ..., 0.0784, 0.0627, 0.0902],\n",
            "           [0.0588, 0.0588, 0.0549,  ..., 0.0784, 0.0667, 0.0941],\n",
            "           [0.0588, 0.0588, 0.0588,  ..., 0.0824, 0.0706, 0.0980]],\n",
            "\n",
            "          [[0.3686, 0.3686, 0.3686,  ..., 0.4863, 0.4863, 0.4863],\n",
            "           [0.3686, 0.3686, 0.3686,  ..., 0.4824, 0.4824, 0.4824],\n",
            "           [0.3686, 0.3686, 0.3686,  ..., 0.4784, 0.4784, 0.4784],\n",
            "           ...,\n",
            "           [0.0510, 0.0510, 0.0549,  ..., 0.0784, 0.0627, 0.0902],\n",
            "           [0.0588, 0.0588, 0.0549,  ..., 0.0784, 0.0667, 0.0941],\n",
            "           [0.0588, 0.0588, 0.0588,  ..., 0.0824, 0.0706, 0.0980]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[0.3608, 0.3647, 0.3725,  ..., 0.4863, 0.4863, 0.4863],\n",
            "           [0.3608, 0.3647, 0.3725,  ..., 0.4824, 0.4824, 0.4824],\n",
            "           [0.3608, 0.3647, 0.3725,  ..., 0.4784, 0.4784, 0.4784],\n",
            "           ...,\n",
            "           [0.0471, 0.0471, 0.0471,  ..., 0.0588, 0.0784, 0.0902],\n",
            "           [0.0471, 0.0471, 0.0510,  ..., 0.0588, 0.0784, 0.0902],\n",
            "           [0.0510, 0.0510, 0.0549,  ..., 0.0588, 0.0784, 0.0941]],\n",
            "\n",
            "          [[0.3686, 0.3686, 0.3686,  ..., 0.4784, 0.4745, 0.4745],\n",
            "           [0.3686, 0.3686, 0.3686,  ..., 0.4784, 0.4745, 0.4745],\n",
            "           [0.3686, 0.3686, 0.3686,  ..., 0.4784, 0.4745, 0.4745],\n",
            "           ...,\n",
            "           [0.0510, 0.0510, 0.0510,  ..., 0.0745, 0.0902, 0.0980],\n",
            "           [0.0510, 0.0510, 0.0510,  ..., 0.0667, 0.0902, 0.0980],\n",
            "           [0.0510, 0.0510, 0.0510,  ..., 0.0627, 0.0941, 0.1020]],\n",
            "\n",
            "          [[0.3686, 0.3686, 0.3686,  ..., 0.4784, 0.4784, 0.4784],\n",
            "           [0.3686, 0.3686, 0.3686,  ..., 0.4784, 0.4784, 0.4784],\n",
            "           [0.3686, 0.3686, 0.3686,  ..., 0.4784, 0.4784, 0.4784],\n",
            "           ...,\n",
            "           [0.0471, 0.0353, 0.0392,  ..., 0.0627, 0.0824, 0.0941],\n",
            "           [0.0471, 0.0353, 0.0392,  ..., 0.0549, 0.0902, 0.0941],\n",
            "           [0.0471, 0.0353, 0.0392,  ..., 0.0471, 0.0941, 0.0941]]],\n",
            "\n",
            "\n",
            "         [[[0.2431, 0.2431, 0.2431,  ..., 0.3882, 0.3882, 0.3882],\n",
            "           [0.2431, 0.2431, 0.2431,  ..., 0.3882, 0.3882, 0.3882],\n",
            "           [0.2431, 0.2431, 0.2431,  ..., 0.3843, 0.3843, 0.3843],\n",
            "           ...,\n",
            "           [0.0157, 0.0157, 0.0118,  ..., 0.0431, 0.0275, 0.0471],\n",
            "           [0.0157, 0.0157, 0.0118,  ..., 0.0353, 0.0196, 0.0471],\n",
            "           [0.0157, 0.0157, 0.0118,  ..., 0.0314, 0.0196, 0.0431]],\n",
            "\n",
            "          [[0.2275, 0.2314, 0.2353,  ..., 0.3882, 0.3882, 0.3882],\n",
            "           [0.2275, 0.2314, 0.2353,  ..., 0.3882, 0.3882, 0.3882],\n",
            "           [0.2275, 0.2314, 0.2353,  ..., 0.3843, 0.3843, 0.3843],\n",
            "           ...,\n",
            "           [0.0078, 0.0078, 0.0078,  ..., 0.0431, 0.0275, 0.0471],\n",
            "           [0.0078, 0.0078, 0.0078,  ..., 0.0353, 0.0196, 0.0471],\n",
            "           [0.0078, 0.0078, 0.0078,  ..., 0.0314, 0.0196, 0.0431]],\n",
            "\n",
            "          [[0.2431, 0.2431, 0.2431,  ..., 0.3882, 0.3882, 0.3882],\n",
            "           [0.2431, 0.2431, 0.2431,  ..., 0.3882, 0.3882, 0.3882],\n",
            "           [0.2431, 0.2431, 0.2431,  ..., 0.3843, 0.3843, 0.3843],\n",
            "           ...,\n",
            "           [0.0078, 0.0078, 0.0078,  ..., 0.0431, 0.0275, 0.0471],\n",
            "           [0.0078, 0.0078, 0.0078,  ..., 0.0353, 0.0196, 0.0471],\n",
            "           [0.0078, 0.0078, 0.0078,  ..., 0.0314, 0.0196, 0.0431]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[0.2353, 0.2275, 0.2235,  ..., 0.3882, 0.3882, 0.3882],\n",
            "           [0.2353, 0.2275, 0.2235,  ..., 0.3882, 0.3882, 0.3882],\n",
            "           [0.2353, 0.2275, 0.2235,  ..., 0.3843, 0.3843, 0.3843],\n",
            "           ...,\n",
            "           [0.0118, 0.0118, 0.0118,  ..., 0.0314, 0.0235, 0.0392],\n",
            "           [0.0118, 0.0118, 0.0118,  ..., 0.0235, 0.0157, 0.0392],\n",
            "           [0.0157, 0.0157, 0.0157,  ..., 0.0196, 0.0118, 0.0353]],\n",
            "\n",
            "          [[0.2431, 0.2431, 0.2431,  ..., 0.3804, 0.3843, 0.3843],\n",
            "           [0.2431, 0.2431, 0.2431,  ..., 0.3804, 0.3843, 0.3843],\n",
            "           [0.2431, 0.2431, 0.2431,  ..., 0.3804, 0.3843, 0.3843],\n",
            "           ...,\n",
            "           [0.0235, 0.0196, 0.0157,  ..., 0.0235, 0.0353, 0.0471],\n",
            "           [0.0235, 0.0196, 0.0157,  ..., 0.0078, 0.0353, 0.0392],\n",
            "           [0.0235, 0.0196, 0.0157,  ..., 0.0039, 0.0314, 0.0392]],\n",
            "\n",
            "          [[0.2431, 0.2431, 0.2431,  ..., 0.3765, 0.3765, 0.3765],\n",
            "           [0.2431, 0.2431, 0.2431,  ..., 0.3765, 0.3765, 0.3765],\n",
            "           [0.2431, 0.2431, 0.2431,  ..., 0.3765, 0.3765, 0.3765],\n",
            "           ...,\n",
            "           [0.0196, 0.0471, 0.0667,  ..., 0.0157, 0.0314, 0.0431],\n",
            "           [0.0196, 0.0471, 0.0667,  ..., 0.0039, 0.0314, 0.0353],\n",
            "           [0.0196, 0.0471, 0.0667,  ..., 0.0000, 0.0353, 0.0314]]]]])\n",
            "tag:   tensor([1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq8v4C63YoDK"
      },
      "source": [
        "## Training Loop"
      ],
      "id": "Lq8v4C63YoDK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4DY_jAqYrtK"
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            if phase == 'train':\n",
        "              for data in train_dataloader:\n",
        "                  data['image'] = data['image'].to(device)\n",
        "                  data['tag'] = data['tag'].to(device)\n",
        "\n",
        "              # zero the parameter gradients\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "              # forward\n",
        "              # track history if only in train\n",
        "              with torch.set_grad_enabled(phase == 'train'):\n",
        "                  outputs = model(data['image'])\n",
        "                  _, preds = torch.max(outputs, 1)\n",
        "                  loss = criterion(outputs, data['tag'])\n",
        "\n",
        "                  # backward + optimize only if in training phase\n",
        "                  if phase == 'train':\n",
        "                      loss.backward()\n",
        "                      optimizer.step()\n",
        "\n",
        "              # statistics\n",
        "              running_loss += loss.item() * data['image'].size(0)\n",
        "              running_corrects += torch.sum(preds == data['tag'])\n",
        "            if phase == 'train':\n",
        "              scheduler.step()\n",
        "    \n",
        "              epoch_loss = running_loss / train_dataloader.__len__\n",
        "              epoch_acc = running_corrects.double() / train_dataloader.__len__\n",
        "            else:\n",
        "              epoch_loss = running_loss / validate_dataloader.__len__\n",
        "              epoch_acc = running_corrects.double() / validate_dataloader.__len__\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "id": "f4DY_jAqYrtK",
      "execution_count": 15,
      "outputs": []
    }
  ]
}