{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "hmdb51.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b17db7ac"
      },
      "source": [
        "### Import packages"
      ],
      "id": "b17db7ac"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hkchx3qMEaWM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e08249ec-1e11-4d22-b03f-4c86350954fb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "Hkchx3qMEaWM",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "643648c0"
      },
      "source": [
        "# !pip install av\n",
        "import torch, torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import cv2\n",
        "import os\n",
        "from os import path\n",
        "import json"
      ],
      "id": "643648c0",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52f767d9"
      },
      "source": [
        "### Extract frames from videos and place them inside video name folder"
      ],
      "id": "52f767d9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73444b38"
      },
      "source": [
        "# def extract_frames(file_path, target_dir):\n",
        "#     if not os.path.exists(target_dir):\n",
        "#         os.makedirs(target_dir)\n",
        "\n",
        "#     vidcap = cv2.VideoCapture(file_path)\n",
        "#     success, image = vidcap.read()\n",
        "#     count = 0\n",
        " \n",
        "#     while success:\n",
        "#       frame_path = os.path.join(target_dir, f'{count}.jpg')\n",
        "#       cv2.imwrite(frame_path, image)     # save frame as JPEG file\n",
        "#       count += 1\n",
        "#       success, image = vidcap.read()\n",
        "#       success, image = vidcap.read()\n",
        "#       success, image = vidcap.read()\n",
        "\n",
        "\n",
        "# root = '/content/drive/MyDrive/mini_dataset'\n",
        "# frame_root = '/content/drive/MyDrive/teste/hmdb51_frames'\n",
        "# labels_path = '/content/drive/MyDrive/teste/labels.csv'\n",
        "# class_name_to_label_path = '/content/drive/MyDrive/teste/class_name_to_label.json'\n",
        "\n",
        "# # read files\n",
        "# files = []\n",
        "\n",
        "# for class_name in os.listdir(root):\n",
        "#     for video_name in os.listdir(os.path.join(root, class_name)):\n",
        "#         files.append([os.path.join(class_name, video_name), class_name])\n",
        "\n",
        "# # normalize labels\n",
        "# class_name_to_label = {}\n",
        "# current_label = -1\n",
        "\n",
        "# for vid in files:\n",
        "#     label = class_name_to_label.get(vid[1], -1)\n",
        "\n",
        "#     if label == -1:\n",
        "#         current_label += 1\n",
        "#         class_name_to_label[vid[1]] = current_label\n",
        "#         label = current_label\n",
        "\n",
        "#     vid[1] = label\n",
        "\n",
        "\n",
        "# # save file paths\n",
        "# if not os.path.exists(os.path.split(labels_path)[0]):\n",
        "#     os.makedirs(os.path.split(labels_path)[0])\n",
        "\n",
        "# f = open(labels_path, 'w')\n",
        "\n",
        "# f.write('path,label\\n')\n",
        "\n",
        "# for vid in files:\n",
        "#     f.write(f'{vid[0]},{vid[1]}\\n')\n",
        "\n",
        "# f.close()\n",
        "\n",
        "# # save label normalization\n",
        "# if not os.path.exists(os.path.split(class_name_to_label_path)[0]):\n",
        "#     os.makedirs(os.path.split(class_name_to_label_path)[0])\n",
        "\n",
        "# with open(class_name_to_label_path, 'w') as json_file:\n",
        "#     json.dump(class_name_to_label, json_file, indent=4)\n",
        "\n",
        "# # extract frames\n",
        "# for i, vid in enumerate(files):\n",
        "#     file_path = os.path.join(root, vid[0])\n",
        "#     target_dir = os.path.join(frame_root, vid[0])\n",
        "\n",
        "#     extract_frames(file_path, target_dir)\n",
        "\n",
        "#     print(f'{i+1}/{len(files)}')\n"
      ],
      "id": "73444b38",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f649ccd"
      },
      "source": [
        "### Split labels csv file into train and validate - 80/20"
      ],
      "id": "6f649ccd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "623bdf86"
      },
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# def split(label):\n",
        "#     path = '/content/drive/MyDrive/teste'\n",
        "#     train = label.sample(frac=0.8, random_state=201)\n",
        "#     val = label.drop(train.index)\n",
        "#     train.to_csv(path + '/train.csv', mode='a', header=False)\n",
        "#     val.to_csv(path + '/val.csv', mode='a', header=False)\n",
        "\n",
        "\n",
        "# root = '/content/drive/MyDrive/teste'\n",
        "# frame_root = '/content/drive/MyDrive/teste/hmdb51_frames'\n",
        "# labels_path = '/content/drive/MyDrive/teste/labels.csv'\n",
        "# class_name_to_label_path = '/content/drive/MyDrive/teste/class_name_to_label.json'\n",
        "\n",
        "# labels_path = '/content/drive/MyDrive/teste/labels.csv'\n",
        "# labels_data = pd.read_csv(labels_path)\n",
        "# last_label = labels_data.tail(1)['label']\n",
        "# last_label = last_label.iloc[0]\n",
        "# max_labels = labels_data.nunique()\n",
        "# max_labels= max_labels['label']\n",
        "# index = 0\n",
        "\n",
        "# for i in range(max_labels):\n",
        "#     label = labels_data[labels_data['label'] == index]\n",
        "#     split(label)\n",
        "#     index +=1 \n"
      ],
      "id": "623bdf86",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b06b0bbb"
      },
      "source": [
        "### Load the images to a model"
      ],
      "id": "b06b0bbb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3805f1c9"
      },
      "source": [
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from skimage import io, transform\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_csv_path = '/content/drive/MyDrive/teste/train.csv'\n",
        "validate_csv_path = '/content/drive/MyDrive/teste/val.csv'\n",
        "root_path = '/content/drive/MyDrive/teste/hmdb51_frames'\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self, frames_csv_file, root_dir):\n",
        "    self.frames_csv = pd.read_csv(frames_csv_file)\n",
        "    self.root_dir = root_dir\n",
        "    self.slice_size = 10\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.frames_csv)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      if torch.is_tensor(idx):\n",
        "          idx = idx.tolist()\n",
        "      \n",
        "      #need to take 10 frames and stack them on 1                                                     #why have to be NOT??? is wrong!! but works..\n",
        "      all_frames = [f for f in os.listdir(os.path.join(self.root_dir, self.frames_csv.iloc[idx, 0])) if not os.path.isfile(f)]\n",
        "      images = []\n",
        "      for frame in all_frames:\n",
        "        path = os.path.join(self.root_dir, self.frames_csv.iloc[idx, 0]) + '/' + frame\n",
        "        images.append(Image.open(path).convert('RGB'))\n",
        "      #random get 10 consecutive frames from all video images\n",
        "      if len(images) > (self.slice_size - 1):\n",
        "        start = random.randrange(len(images) - 10)\n",
        "        frames = images[start: start + self.slice_size]\n",
        "      #tranform all the frames in 1 tensor\n",
        "      final_image = self.transform(frames)\n",
        "    \n",
        "      tag = self.frames_csv.iloc[idx, 1]\n",
        "      sample = {'image': final_image, 'tag': tag}\n",
        "      return sample\n",
        "\n",
        "  def transform(self, frames):\n",
        "    #random crop\n",
        "    #random horizontal flip\n",
        "    #transform to tensor and stack\n",
        "    frames_tensors = []\n",
        "    for frame in frames:\n",
        "      frame = TF.to_tensor(frame)\n",
        "      print(frame.shape)\n",
        "      frames_tensors.append(frame)\n",
        "    final_tensor = torch.stack(frames_tensors, dim=1)\n",
        "    print('final')\n",
        "    print(final_tensor.shape)\n",
        "    return final_tensor\n",
        "\n",
        "train_dataset = MyDataset(train_csv_path, root_path)\n",
        "validate_dataset = MyDataset(validate_csv_path, root_path)\n",
        "\n"
      ],
      "id": "3805f1c9",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IujiHxXEUMH"
      },
      "source": [
        "## Dataloaders"
      ],
      "id": "0IujiHxXEUMH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFRJQ66ZER4P",
        "outputId": "d4988cc2-1eaf-4c1d-bd28-f2715607dbcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "validate_dataloader = DataLoader(validate_dataset, batch_size=10, shuffle=True)\n",
        "\n",
        "input, tag = iter(train_dataloader).next()\n"
      ],
      "id": "jFRJQ66ZER4P",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-b6b8cd220c95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalidate_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-d94e900ae925>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0;31m#need to take 10 frames and stack them on 1                                                     #why have to be NOT??? is wrong!! but works..\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m       \u001b[0mall_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframes_csv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m       \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/posixpath.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0mpath\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBytesWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mgenericpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_arg_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'join'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/genericpath.py\u001b[0m in \u001b[0;36m_check_arg_types\u001b[0;34m(funcname, *args)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             raise TypeError('%s() argument must be str or bytes, not %r' %\n\u001b[0;32m--> 153\u001b[0;31m                             (funcname, s.__class__.__name__)) from None\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasstr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasbytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't mix strings and bytes in path components\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: join() argument must be str or bytes, not 'int64'"
          ]
        }
      ]
    }
  ]
}