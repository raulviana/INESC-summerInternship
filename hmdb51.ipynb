{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "name": "hmdb51.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b17db7ac"
      },
      "source": [
        "### Import packages"
      ],
      "id": "b17db7ac"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hkchx3qMEaWM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "682d5de7-78d4-4bc1-bca6-30b195c77e59"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "Hkchx3qMEaWM",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "643648c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6720e95f-8304-477b-eaf5-f1f682bfb4d2"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import cv2\n",
        "import os\n",
        "from os import path\n",
        "import json\n",
        "import time\n",
        "import copy\n",
        "\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "#if gpu, use it\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "id": "643648c0",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52f767d9"
      },
      "source": [
        "### Extract frames from videos and place them inside video name folder"
      ],
      "id": "52f767d9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73444b38"
      },
      "source": [
        "# def extract_frames(file_path, target_dir):\n",
        "#     if not os.path.exists(target_dir):\n",
        "#         os.makedirs(target_dir)\n",
        "\n",
        "#     vidcap = cv2.VideoCapture(file_path)\n",
        "#     success, image = vidcap.read()\n",
        "#     count = 0\n",
        " \n",
        "#     while success:\n",
        "#       frame_path = os.path.join(target_dir, f'{count}.jpg')\n",
        "#       cv2.imwrite(frame_path, image)     # save frame as JPEG file\n",
        "#       count += 1\n",
        "#       success, image = vidcap.read()\n",
        "#       success, image = vidcap.read()\n",
        "#       success, image = vidcap.read()\n",
        "\n",
        "\n",
        "# root = '/content/drive/MyDrive/mini_dataset'\n",
        "# frame_root = '/content/drive/MyDrive/teste/hmdb51_frames'\n",
        "# labels_path = '/content/drive/MyDrive/teste/labels.csv'\n",
        "# class_name_to_label_path = '/content/drive/MyDrive/teste/class_name_to_label.json'\n",
        "\n",
        "# # read files\n",
        "# files = []\n",
        "\n",
        "# for class_name in os.listdir(root):\n",
        "#     for video_name in os.listdir(os.path.join(root, class_name)):\n",
        "#         files.append([os.path.join(class_name, video_name), class_name])\n",
        "\n",
        "# # normalize labels\n",
        "# class_name_to_label = {}\n",
        "# current_label = -1\n",
        "\n",
        "# for vid in files:\n",
        "#     label = class_name_to_label.get(vid[1], -1)\n",
        "\n",
        "#     if label == -1:\n",
        "#         current_label += 1\n",
        "#         class_name_to_label[vid[1]] = current_label\n",
        "#         label = current_label\n",
        "\n",
        "#     vid[1] = label\n",
        "\n",
        "\n",
        "# # save file paths\n",
        "# if not os.path.exists(os.path.split(labels_path)[0]):\n",
        "#     os.makedirs(os.path.split(labels_path)[0])\n",
        "\n",
        "# f = open(labels_path, 'w')\n",
        "\n",
        "# f.write('path,label\\n')\n",
        "\n",
        "# for vid in files:\n",
        "#     f.write(f'{vid[0]},{vid[1]}\\n')\n",
        "\n",
        "# f.close()\n",
        "\n",
        "# # save label normalization\n",
        "# if not os.path.exists(os.path.split(class_name_to_label_path)[0]):\n",
        "#     os.makedirs(os.path.split(class_name_to_label_path)[0])\n",
        "\n",
        "# with open(class_name_to_label_path, 'w') as json_file:\n",
        "#     json.dump(class_name_to_label, json_file, indent=4)\n",
        "\n",
        "# # extract frames\n",
        "# for i, vid in enumerate(files):\n",
        "#     file_path = os.path.join(root, vid[0])\n",
        "#     target_dir = os.path.join(frame_root, vid[0])\n",
        "\n",
        "#     extract_frames(file_path, target_dir)\n",
        "\n",
        "#     print(f'{i+1}/{len(files)}')\n"
      ],
      "id": "73444b38",
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f649ccd"
      },
      "source": [
        "### Split labels csv file into train and validate - 80/20"
      ],
      "id": "6f649ccd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "623bdf86"
      },
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# def split(label):\n",
        "#     path = '/content/drive/MyDrive/teste'\n",
        "#     train = label.sample(frac=0.8, random_state=201)\n",
        "#     val = label.drop(train.index)\n",
        "#     train.to_csv(path + '/train.csv', mode='a', header=False)\n",
        "#     val.to_csv(path + '/val.csv', mode='a', header=False)\n",
        "\n",
        "\n",
        "# root = '/content/drive/MyDrive/teste'\n",
        "# frame_root = '/content/drive/MyDrive/teste/hmdb51_frames'\n",
        "# labels_path = '/content/drive/MyDrive/teste/labels.csv'\n",
        "# class_name_to_label_path = '/content/drive/MyDrive/teste/class_name_to_label.json'\n",
        "\n",
        "# labels_path = '/content/drive/MyDrive/teste/labels.csv'\n",
        "# labels_data = pd.read_csv(labels_path)\n",
        "# last_label = labels_data.tail(1)['label']\n",
        "# last_label = last_label.iloc[0]\n",
        "# max_labels = labels_data.nunique()\n",
        "# max_labels= max_labels['label']\n",
        "# index = 0\n",
        "\n",
        "# for i in range(max_labels):\n",
        "#     label = labels_data[labels_data['label'] == index]\n",
        "#     split(label)\n",
        "#     index +=1 \n"
      ],
      "id": "623bdf86",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b06b0bbb"
      },
      "source": [
        "### Custom Dataset"
      ],
      "id": "b06b0bbb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3805f1c9"
      },
      "source": [
        "train_csv_path = '/content/drive/MyDrive/teste/train.csv'\n",
        "validate_csv_path = '/content/drive/MyDrive/teste/val.csv'\n",
        "root_path = '/content/drive/MyDrive/teste/hmdb51_frames'\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self, frames_csv_file, root_dir):\n",
        "    self.frames_csv = pd.read_csv(frames_csv_file)\n",
        "    self.root_dir = root_dir\n",
        "    self.slice_size = 10\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.frames_csv)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "      if torch.is_tensor(idx):\n",
        "          idx = idx.tolist()\n",
        "      \n",
        "      #need to take 10 frames and stack them on 1 tensor                                                    \n",
        "      #()-> second index has to be 1 because id column (3 columns) \n",
        "      #()-> why have to be NOT??? is wrong!! but works..\n",
        "      all_frames = [f for f in os.listdir(os.path.join(self.root_dir, str(self.frames_csv.iloc[idx, 1]))) if not os.path.isfile(f)]\n",
        "      #random get 10 consecutive frames from all video frames in folder\n",
        "      if len(all_frames) > (self.slice_size):\n",
        "        start = random.randrange(len(all_frames) - self.slice_size)\n",
        "        frames = all_frames[start: start + self.slice_size]\n",
        "      else:\n",
        "        frames = all_frames\n",
        "      \n",
        "      images = []\n",
        "      #load the images\n",
        "      for frame in frames:\n",
        "        path = os.path.join(self.root_dir, str(self.frames_csv.iloc[idx, 1])) + '/' + frame\n",
        "        images.append(Image.open(path).convert('RGB'))\n",
        "      \n",
        "      #apply tansforms and condense all the images in 1 tensor\n",
        "      final_image = self.transform(images)\n",
        "      tag = int(self.frames_csv.iloc[idx, 2])\n",
        "      return final_image, tag\n",
        "\n",
        "  def transform(self, images):\n",
        "    #random crop\n",
        "    #random horizontal flip\n",
        "    #transform to tensor and stack\n",
        "    frames_tensors = []\n",
        "    for image in images:\n",
        "      #rezise image\n",
        "      newsize = (240, 320)\n",
        "      image = image.resize(newsize)\n",
        "      image_tensor = TF.to_tensor(image)\n",
        "      frames_tensors.append(image_tensor)\n",
        "    final_tensor = torch.stack(frames_tensors, dim=1)\n",
        "    #normalize\n",
        "\n",
        "    return final_tensor\n",
        "\n",
        "train_dataset = MyDataset(train_csv_path, root_path)\n",
        "validate_dataset = MyDataset(validate_csv_path, root_path)\n"
      ],
      "id": "3805f1c9",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IujiHxXEUMH"
      },
      "source": [
        "## Dataloaders"
      ],
      "id": "0IujiHxXEUMH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFRJQ66ZER4P"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "validate_dataloader = DataLoader(validate_dataset, batch_size=1, shuffle=True)\n"
      ],
      "id": "jFRJQ66ZER4P",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq8v4C63YoDK"
      },
      "source": [
        "## Training Loop"
      ],
      "id": "Lq8v4C63YoDK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4DY_jAqYrtK"
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "    \n",
        "    stats = {}\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            if phase == 'train':\n",
        "              for data, tag in train_dataloader:\n",
        "                  data = data.to(device)\n",
        "                  tag = tag.to(device)\n",
        "\n",
        "              # zero the parameter gradients\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "              # forward\n",
        "              # track history if only in train\n",
        "              with torch.set_grad_enabled(phase == 'train'):\n",
        "                  outputs = model(data)\n",
        "                  _, preds = torch.max(outputs, 1)\n",
        "                  loss = criterion(outputs, tag)\n",
        "\n",
        "                  # backward + optimize only if in training phase\n",
        "                  loss.backward()\n",
        "                  optimizer.step()\n",
        "\n",
        "              # statistics\n",
        "              running_loss += loss.item() * data.size(0)\n",
        "              running_corrects += torch.sum(preds == tag)\n",
        "            \n",
        "              scheduler.step()\n",
        "              epoch_loss = running_loss / len(train_dataloader)\n",
        "              epoch_acc = running_corrects.double() / len(train_dataloader)\n",
        "            else:\n",
        "              for data, tag in validate_dataloader:\n",
        "                data = data.to(device)\n",
        "                tag = tag.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(data)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, tag)\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * data.size(0)\n",
        "                running_corrects += torch.sum(preds == tag)\n",
        "          \n",
        "              epoch_loss = running_loss / len(validate_dataloader)\n",
        "              epoch_acc = running_corrects.double() / len(validate_dataloader)\n",
        "              stats[phase + '_loss'].append(epoch_loss)\n",
        "              stats[phase + '_acc'].append(epoch_acc)\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "id": "f4DY_jAqYrtK",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhXQGThb-qbo"
      },
      "source": [
        "## Prepare the model"
      ],
      "id": "lhXQGThb-qbo"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VutojGxn-0k7"
      },
      "source": [
        "\n",
        "f = open('/content/drive/MyDrive/teste/class_name_to_label.json')\n",
        "classes = json.load(f)\n",
        "f.close()\n",
        "\n",
        "model_ft = torchvision.models.video.r3d_18(pretrained=False, progress=True)\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "# Here the size of each output sample is set to 2.\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model_ft.fc = nn.Linear(num_ftrs, len(classes))\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "id": "VutojGxn-0k7",
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxtRwUrhAxFz"
      },
      "source": [
        "## Train and Evaluate"
      ],
      "id": "dxtRwUrhAxFz"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSyhCKyLA0T3",
        "outputId": "bacf6281-dca3-4e32-b5ce-e6eac4a2f1e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=3)"
      ],
      "id": "sSyhCKyLA0T3",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/2\n",
            "----------\n",
            "train Loss: 0.0010 Acc: 0.0030\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-7b408c339761>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[0;32m----> 2\u001b[0;31m                        num_epochs=3)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-68-cfe353851867>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     68\u001b[0m               \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunning_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m               \u001b[0mepoch_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunning_corrects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m               \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m               \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_loss'"
          ]
        }
      ]
    }
  ]
}